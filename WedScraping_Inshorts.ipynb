{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c6f33f8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# !pip3 install pymongo\n",
    "import requests\n",
    "import html5lib\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from pymongo import MongoClient\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da9a5d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "news_type = ['national','technology','politics','entertainment','world','sports','business','science','automobile','startup','miscellaneous','hatke']\n",
    "url = \"https://www.inshorts.com/en/read/\"\n",
    "urls = []\n",
    "for each in news_type:\n",
    "    urls.append(url+each)\n",
    "\n",
    "def connect(url):\n",
    "    req = requests.get(url)\n",
    "    soup = bs(req.text, \"html5lib\")\n",
    "    container = soup.find('div',{'class':'card-stack'})\n",
    "    return container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9fc5c3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def fetch_all_news(soup):\n",
    "    data = {'headline':[],'link':[],'author':[],'content':[],'time':[],'date':[],'day':[],'source':[],'source_link':[],'news_type':[]}\n",
    "    for url in urls:\n",
    "        container = connect(url)\n",
    "        news_type = url.split(\"/\")[5]\n",
    "        if (news_type == 'miscellaneous' or news_type == 'hatke'):\n",
    "            news_type = 'others'\n",
    "        for i in container.findAll('div',{'class':'news-card z-depth-1'}):\n",
    "            #Headline\n",
    "            try:\n",
    "                headline = (i.a.text).strip()\n",
    "                data['headline'].append(headline)\n",
    "            except AttributeError:\n",
    "                data['headline'].append('data not found')\n",
    "                \n",
    "            #Link\n",
    "            try:\n",
    "                link = i.a['href']\n",
    "                data['link'].append(link)\n",
    "            except AttributeError:\n",
    "                data['link'].append('data not found')\n",
    "        \n",
    "            #Author\n",
    "            try:\n",
    "                author = i.find('span',{'class':'author'}).text\n",
    "                data['author'].append(author)\n",
    "            except AttributeError:\n",
    "                data['author'].append('data not found')\n",
    "            \n",
    "            #Time\n",
    "            try:\n",
    "                time = i.find('span',{'class':'time'}).text\n",
    "                t_obj = datetime.strptime(time,'%I:%M %p')\n",
    "                t_fmt = datetime.strftime(t_obj,'%H:%M:%S')\n",
    "                data['time'].append(t_fmt)  \n",
    "            except AttributeError:\n",
    "                data['time'].append('data not found')\n",
    "            \n",
    "            #Date, Day\n",
    "            try:\n",
    "                dd = i.find('span',{'clas':'date'}).text\n",
    "                lst = dd.split(\",\")\n",
    "                date = lst[0]\n",
    "                day = lst[1]\n",
    "                d = datetime.strptime(date, \"%d %b %Y\")\n",
    "                d_fmt = d.strftime(\"%d-%m-%Y\")\n",
    "                data['date'].append(d_fmt)\n",
    "                data['day'].append(day)\n",
    "            except AttributeError:\n",
    "                data['date'].append('data not found')\n",
    "                data['day'].append('data not found')\n",
    "                \n",
    "            #Content\n",
    "            try:\n",
    "                content = (i.find('div',{'itemprop':'articleBody'})).text\n",
    "                content = content.replace('\\\\','')\n",
    "                data['content'].append(content)\n",
    "            except AttributeError:\n",
    "                data['content'].append('data not found')\n",
    "            \n",
    "            #Source\n",
    "            try:\n",
    "                source = (i.find('div',{'class':'read-more'})).a.text\n",
    "                data['source'].append(source)\n",
    "            except AttributeError:\n",
    "                data['source'].append('data not found')\n",
    "            \n",
    "            #Source_link\n",
    "            try:\n",
    "                source_link = (i.find('div',{'class':'read-more'})).a['href']\n",
    "                data['source_link'].append(source_link)\n",
    "            except AttributeError:\n",
    "                data['source_link'].append('data not found')\n",
    "                \n",
    "            #News_type\n",
    "            data['news_type'].append(news_type)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c4b0f26f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "headline       object\n",
      "link           object\n",
      "author         object\n",
      "content        object\n",
      "time           object\n",
      "date           object\n",
      "day            object\n",
      "source         object\n",
      "source_link    object\n",
      "news_type      object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(fetch_all_news(urls))\n",
    "print(df.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18fd2a15",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    A flight from Russia to Goa was diverted to Uz...\n",
       "1    Mumbai Police have said that they have arreste...\n",
       "2    Enforcement Directorate (ED) has arrested TMC ...\n",
       "3    The Bombay High Court on Friday rejected a ple...\n",
       "4    Three workers are suspected to be trapped insi...\n",
       "Name: content, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['content'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2aeccf27",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pymongo.results.InsertManyResult at 0x2454b118cd0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client = MongoClient('mongodb+srv://root:root8642@cluster0.u4narnb.mongodb.net/?retryWrites=true&w=majority')\n",
    "db = client['my_project']\n",
    "collection = db['news_data']\n",
    "\n",
    "# df.reset_index(inplace=True)\n",
    "# df.rename(columns={df.index.name:'_id'})\n",
    "# df.index = df.index.set_names(['_id'])\n",
    "# df.drop(['level_0'], axis=1, inplace=True)\n",
    "\n",
    "data_dict = df.to_dict('records')\n",
    "# print(data_dict)\n",
    "collection.insert_many(data_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317d5dac",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
